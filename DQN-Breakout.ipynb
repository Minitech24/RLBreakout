{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kevFile_DQN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ra5MevXgYSif",
        "outputId": "51746a77-54d9-43d4-daaf-5616f4774eb2"
      },
      "source": [
        "\"\"\"!pip install gym\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!pip install gym\\n!apt-get install python-opengl -y\\n!apt install xvfb -y'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkMeuqHsaIM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fe1e33-cd9e-4b35-ffc5-5cfd11fc99dd"
      },
      "source": [
        "%matplotlib inline\n",
        "from gym import wrappers\n",
        "from time import sleep\n",
        "import time\n",
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#interacting with the file system\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython: from IPython import display\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhWXThwca31G"
      },
      "source": [
        "# google deep mind paper\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, img_height, img_width, num_frames=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.dense = torch.nn.Linear(64 * 7 * 7, 512)\n",
        "        self.out = nn.Linear(512, 4)            \n",
        "\n",
        "        \n",
        "    def forward(self, t):\n",
        "        t = F.relu(self.conv1(t))\n",
        "        t = F.relu(self.conv2(t))\n",
        "        t = F.relu(self.conv3(t))\n",
        "        t = t.view(t.size(0), -1)\n",
        "        t = F.relu(self.dense(t))\n",
        "        t = self.out(t)\n",
        "        return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWia6olXa4fN"
      },
      "source": [
        "Experience = namedtuple(\n",
        "    'Experience',\n",
        "    ('state', 'action', 'next_state', 'reward')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajUJdLIia6ab"
      },
      "source": [
        "class ReplayMemory():\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.push_count = 0\n",
        "        \n",
        "    def push(self, experience):\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(experience)\n",
        "        else:\n",
        "            self.memory[self.push_count % self.capacity] = experience\n",
        "        self.push_count += 1\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "    \n",
        "    def can_provide_sample(self, batch_size):\n",
        "        return len(self.memory) >= batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfMK1ALQa8Eq"
      },
      "source": [
        "class EpsilonGreedyStrategy():\n",
        "    def __init__(self, start, end, decay):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.decay = decay\n",
        "    \n",
        "    def get_exploration_rate(self, current_step):\n",
        "        return self.end + (self.start - self.end) * \\\n",
        "            math.exp(-1. * current_step * self.decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ugf2J4a-MB"
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, strategy, num_actions, device):\n",
        "        self.current_step = 0\n",
        "        self.strategy = strategy\n",
        "        self.num_actions = num_actions\n",
        "        self.device = device\n",
        "\n",
        "    def select_action(self, state, policy_net):\n",
        "        rate = strategy.get_exploration_rate(self.current_step)\n",
        "        self.current_step += 1\n",
        "\n",
        "        if rate > random.random():\n",
        "            action = random.randrange(self.num_actions)\n",
        "            return torch.tensor([action]).to(self.device) # explore      \n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                return policy_net(state).argmax(dim=1).to(self.device) # exploit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OqovxusbATS"
      },
      "source": [
        "def plot(values, moving_avg_period, time_taken):\n",
        "    plt.figure(2)\n",
        "    plt.clf()        \n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Points')\n",
        "    plt.plot(values)\n",
        "    \n",
        "    moving_avg = get_moving_average(moving_avg_period, values)\n",
        "    plt.plot(moving_avg)    \n",
        "    plt.pause(0.001)\n",
        "    print(\"Episode\", len(values), \"\\n\", \\\n",
        "          moving_avg_period, \"episode moving avg:\", moving_avg[-1])\n",
        "    print(f\"Episode times: {time_taken[-1]} (s)\")\n",
        "    if is_ipython: display.clear_output(wait=True)\n",
        "\n",
        "def get_moving_average(period, values):\n",
        "    values = torch.tensor(values, dtype=torch.float)\n",
        "    if len(values) >= period:\n",
        "        moving_avg = values.unfold(dimension=0, size=period, step=1) \\\n",
        "            .mean(dim=1).flatten(start_dim=0)\n",
        "        moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
        "        return moving_avg.numpy()\n",
        "    else:\n",
        "        moving_avg = torch.zeros(len(values))\n",
        "        return moving_avg.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdz7wRNRbCs7"
      },
      "source": [
        "def extract_tensors(experiences):\n",
        "    # Convert batch of Experiences to Experience of batches\n",
        "    batch = Experience(*zip(*experiences))\n",
        "\n",
        "    t1 = torch.cat(batch.state)\n",
        "    t2 = torch.cat(batch.action)\n",
        "    t3 = torch.cat(batch.reward)\n",
        "    t4 = torch.cat(batch.next_state)\n",
        "\n",
        "    return (t1,t2,t3,t4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_kh4ALxbFfU"
      },
      "source": [
        "class QValues():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_current(policy_net, states, actions):\n",
        "        return policy_net(states).gather(dim=1, index=actions.unsqueeze(-1))\n",
        "    \n",
        "    @staticmethod        \n",
        "    def get_next(target_net, next_states):                \n",
        "        final_state_locations = next_states.flatten(start_dim=1) \\\n",
        "            .max(dim=1)[0].eq(0).type(torch.bool)\n",
        "        non_final_state_locations = (final_state_locations == False)\n",
        "        non_final_states = next_states[non_final_state_locations]\n",
        "        batch_size = next_states.shape[0]\n",
        "        values = torch.zeros(batch_size).to(QValues.device)\n",
        "        values[non_final_state_locations] = target_net(non_final_states).max(dim=1)[0].detach()\n",
        "        return values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEKyPS-IbH2g"
      },
      "source": [
        "class BreakoutEnvManager():\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.env = gym.make('BreakoutNoFrameskip-v4').unwrapped\n",
        "        self.env = wrappers.AtariPreprocessing(self.env)\n",
        "        self.env = wrappers.FrameStack(self.env, num_stack = 4)\n",
        "        self.env.reset()\n",
        "        self.current_screen = None\n",
        "        self.done = False\n",
        "    \n",
        "    def reset(self):\n",
        "        self.env.reset()\n",
        "        self.current_screen = None\n",
        "        \n",
        "    def close(self):\n",
        "        self.env.close()\n",
        "        \n",
        "    def render(self, mode='human'):\n",
        "        return self.env.render(mode)\n",
        "        \n",
        "    def num_actions_available(self):\n",
        "        return self.env.action_space.n\n",
        "        \n",
        "    def take_action(self, action):        \n",
        "        _, reward, self.done, _ = self.env.step(action.item())\n",
        "        return torch.tensor([reward], device=self.device)\n",
        "    \n",
        "    def just_starting(self):\n",
        "        return self.current_screen is None\n",
        "    \n",
        "    def get_state(self):\n",
        "        self.current_screen = self.get_processed_screen()\n",
        "        return self.current_screen\n",
        "\n",
        "    \n",
        "    def get_screen_height(self):\n",
        "        screen = self.get_processed_screen()\n",
        "        #print(screen, \"Get height\", screen.shape)\n",
        "        return screen.shape[2]\n",
        "    \n",
        "    def get_screen_width(self):\n",
        "        screen = self.get_processed_screen()\n",
        "        return screen.shape[3]\n",
        "       \n",
        "    def get_processed_screen(self):\n",
        "        #frame = np.array(obs[0])[f]\n",
        "        screen = np.asarray(self.env.frames) # PyTorch expects CHW\n",
        "        #print(\"Screen shape get process\", screen.shape)\n",
        "        return self.transform_screen_data(screen)\n",
        "    \n",
        "    def transform_screen_data(self, screen):       \n",
        "        # Convert to float, rescale, convert to tensor\n",
        "        #print(\"Shape screen\", screen.shape)\n",
        "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "        screen = torch.from_numpy(screen)\n",
        "        \n",
        "        return screen.unsqueeze(0).to(self.device) # add a batch dimension (BCHW)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBX2BkE9VC1M"
      },
      "source": [
        "def save_state(episode, policy_net, target_net, optimizer, agent):\n",
        "    state = {\n",
        "      'episode': episode,\n",
        "      'policy_state_dict': policy_net.state_dict(),\n",
        "      'target_state_dict': target_net.state_dict(),\n",
        "      'optimizer': optimizer.state_dict(),\n",
        "      'agent_current_step': agent.current_step\n",
        "    }\n",
        "\n",
        "    model_save_name = 'classifier.pt'\n",
        "    filepath = f\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
        "    torch.save(state, filepath)\n",
        "\n",
        "    \n",
        "    model_save_name = f'classifier_{episode}config{configuration}.pt'\n",
        "    filepath = f\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
        "    torch.save(state, filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "ewmLZl2pbKSM",
        "outputId": "72590e69-fabe-45a7-ce50-dba473fd3735"
      },
      "source": [
        "batch_size = 256\n",
        "gamma = 0.999\n",
        "eps_start = 1\n",
        "eps_end = 0.01\n",
        "eps_decay = 0.001\n",
        "target_update = 10\n",
        "memory_size = 100000\n",
        "lr = 0.001 #\n",
        "num_episodes = 8500 # run for more episodes for better results\n",
        "configuration = 1 \n",
        "\n",
        "last_ep_cp = 0\n",
        "#Load model\n",
        "last_ep_cp = 6000\n",
        "model_save_name = f'classifier_{last_ep_cp}config{configuration}.pt'\n",
        "path = f\"/content/gdrive/My Drive/models/{model_save_name}\"\n",
        "\n",
        "checkpoint = torch.load(path) #\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "em = BreakoutEnvManager(device)\n",
        "\n",
        "\n",
        "#ADDED\n",
        "#print(em.env.frames)\n",
        "#print(np.asarray(em.env.frames[0]).shape)\n",
        "strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
        "#agent gives you the proper epsilon value\n",
        "agent = Agent(strategy, em.num_actions_available(), device)\n",
        "agent.current_step = checkpoint['agent_current_step'] #\n",
        "memory = ReplayMemory(memory_size)\n",
        "\n",
        "\n",
        "policy_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
        "policy_net.load_state_dict(checkpoint['policy_state_dict']) #\n",
        "policy_net.eval()\n",
        "\n",
        "target_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
        "target_net.load_state_dict(checkpoint['target_state_dict']) #\n",
        "target_net.load_state_dict(policy_net.state_dict()) #\n",
        "target_net.eval()\n",
        "optimizer = optim.Adam(params=policy_net.parameters(), lr=lr)\n",
        "optimizer.load_state_dict(checkpoint['optimizer']) #\n",
        "\n",
        "episode_points = []\n",
        "episode_times = []\n",
        "for episode in range(last_ep_cp+1, last_ep_cp+num_episodes):\n",
        "\n",
        "    if episode % 500 == 0:\n",
        "      save_state(episode, policy_net, target_net, optimizer, agent)\n",
        "\n",
        "    start_time = time.time()\n",
        "    em.reset()\n",
        "    total_reward = 0\n",
        "    state = em.get_state()\n",
        "    render_game = False #(episode > 1) and (episode % 900 == 0)\n",
        "\n",
        "    for timestep in count():\n",
        "        if render_game: em.render()\n",
        "        action = agent.select_action(state, policy_net)\n",
        "        reward = em.take_action(action)\n",
        "        total_reward += reward\n",
        "        next_state = em.get_state()\n",
        "        memory.push(Experience(state, action, next_state, reward))\n",
        "        state = next_state\n",
        "\n",
        "        if memory.can_provide_sample(batch_size):\n",
        "            experiences = memory.sample(batch_size)\n",
        "            states, actions, rewards, next_states = extract_tensors(experiences)\n",
        "            \n",
        "            current_q_values = QValues.get_current(policy_net, states, actions)\n",
        "            next_q_values = QValues.get_next(target_net, next_states)\n",
        "            target_q_values = (next_q_values * gamma) + rewards\n",
        "\n",
        "            loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        if em.done:\n",
        "            episode_points.append(total_reward)\n",
        "\n",
        "            end_time = time.time()\n",
        "            time_elapsed = end_time - start_time\n",
        "            episode_times.append(time_elapsed)\n",
        "\n",
        "            if episode %50 == 0:\n",
        "              plot(episode_points, 100, episode_times)\n",
        "              np.savetxt(\"config_1_ep_points.csv\", episode_points, delimiter =\",\")\n",
        "              np.savetxt(\"config_1_ep_times.csv\", episode_times, delimiter=\",\")\n",
        "            break\n",
        "\n",
        "    if episode % target_update == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "        \n",
        "em.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-95a19bb88171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/gdrive/My Drive/models/{model_save_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    136\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btcyxirUfJxM"
      },
      "source": [
        "plot(episode_points, 100, episode_times)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJp9BCv0h0We"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}